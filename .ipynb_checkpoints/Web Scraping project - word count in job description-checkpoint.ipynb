{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests #allows programmer to send HTTP requests \n",
    "from bs4 import BeautifulSoup #imports python library that allows for scraping the web\n",
    "import collections #collections provides solutions that would be tricky to implement\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer #imports Natural Language Processing functions\n",
    "import pandas as pd #imports pandas, a Python library \n",
    "from operator import itemgetter #The operator modules exports a set of efficient functions corresponding to intrinsic \n",
    "#operators in python(i.e. +,-,*,etc.). Itemgetter allows programmer to retrieve something from a data structure much faster and easier\n",
    "import numpy as np #imports numpy, a Python library that allows for simple and complex arithmetic calculations \n",
    "import nltk #imports natural language toolkit\n",
    "from nltk.corpus import stopwords #imports stopwords function from natural language toolkit so that all stop words(i.e. and, is, but) can be filtered out\n",
    "from nltk.tokenize import word_tokenize #imports word_tokenize function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(\"https://www.linkedin.com/jobs/view/791327763/\") #gives you access to webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page.status_code #checks to see whether getting access to webpage was successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page.content #shows content of page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content, \"html.parser\") #parsing webspage using HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soup.prettify()) #organizes content of webpage so that it is easier to read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all('meta') #finds all text within web page with the meta tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(soup.find_all('meta')) #calculates the number of tags with the meta tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = soup.find_all('meta')[22] #stores the contents of the 22nd tag with the meta tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text #shows the content of text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_text = soup.find('meta', property='og:description') #finds section of text with meta tag and property = 'og:description'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mega_text = my_text.get(\"content\") #gets the content of that meta tag and stores it in mega_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mega_text #shows content of mega_text "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating empty dictionary so that the word and its word count in main body of job description can be stored in this dictionary. The problem with this approach is that there are way too many duplilcates in dictionary plus there are numerous stop words with the highest word counts in job description that will need to be removed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "word_dict = {} #initializes empty dictionary \n",
    "for i in mega_text.split(): #loops through each word in mega_text\n",
    "    print(i, mega_text.count(i)) #prints word and its word count in mega_text \n",
    "    word_dict[i] = mega_text.count(i) #stores word and word count in word_dict dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dict #prints contents of dictionary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this approach, the Count Vectorizer(a Natural Language Processing technique) function is used to compute the word count of each word in main body of job description. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(stop_words=['and', 'And', 'to', 'or', 'a'] ) #initializes CountVectorizer function with specific stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.fit(mega_text.split()) #fits all of the words inside mega_text with CountVectorizer function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_all = cv.transform(mega_text.split()) #transforms words with CountVectorizer function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_all #displays contents of cv_all, which is currently a sparse matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(cv_all) #shows the data type of cv_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_df = pd.DataFrame(cv_all.todense(), columns=cv.get_feature_names()) #converts the sparse matrix cv_all into Data Frame cv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_df.shape #shows the number of rows and columns in new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 0 #initializes j to 0\n",
    "for i in mega_text.split(): #loops through words in mega_text\n",
    "    j+=1 #increments j\n",
    "\n",
    "print(j) #prints j, or the number of words that are in mega_text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_df.columns #shows the columns in cv_df dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_dict = {} #initializes empty dictionary \n",
    "for i in cv_df.columns: #loops through columns in cv_df dataframe\n",
    "    w_dict[i] = cv_df[i].sum() #stores the word as key and its word count as a value in w_dict dictionary \n",
    "    \n",
    "print(w_dict) #prints the contents of dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(w_dict.items(), key=lambda x:x[1], reverse=True) #takes the word count of every word in mega_text and sorts it from highest \n",
    "#word count to lowest word count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uses OrderedDict function in order to sort the word count of each word from highest to lowest \n",
    "d = collections.OrderedDict(sorted(w_dict.items(), key=itemgetter(1), reverse=True)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d #generates content of d "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Natural Language Toolkit(NLTK) to determine word count so that all of the stop words can be filtered with just a couple of lines of code. Provides a faster and more efficient way of determining the word count of only words that matter in a job description "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.__version__ #gets current version of nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words =set(stopwords.words('English')) #finds all of the stop words in the English language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_words = [i for i in mega_text.split() if i not in stop_words] #gathers a list of non-stopwords from the meta tag job description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_words #shows all of the real words(non-stopwords )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dict1 = {} #creates empty dictionary \n",
    "for i in real_words: #loops through all of the non-stopwords in job description \n",
    "    print(i, real_words.count(i)) #prints the non-stopwords along with its word count \n",
    "    word_dict1[i] = mega_text.count(i) #stores non-stopword as a key and its word count as a value in dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dict1 #generates contents of dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(word_dict1.items(), key=itemgetter(1), reverse=True) #takes the word count of each non-stopword and stores it in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
